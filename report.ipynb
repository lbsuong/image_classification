{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "report.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CUonWD1uh_QS",
        "D_5mOU7lorJf"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1Ct8kRnL8KT"
      },
      "source": [
        "# **1. Mô tả ứng dụng** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb9VTl4EkEhu"
      },
      "source": [
        "## **Ứng dụng mà nhóm chọn**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxpYMlTEQMwf"
      },
      "source": [
        "Huấn luyện Convolutional Neural Network để phân lớp ảnh bằng Stochastic Gradient Descent.\n",
        "*   **Input:** Tập dữ liệu ảnh và nhãn của ảnh, cấu trúc của CNN và các tham số liên quan.\n",
        "\n",
        "*   **Output:** Mô hình phân lớp ảnh sau khi huấn luyện.\n",
        "\n",
        "*   **Ý nghĩa của ứng dụng trong thực tế:** Giúp số hoá tài liệu, OCR..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RZhoTOskHWS"
      },
      "source": [
        "## **Ứng dụng này có cần phải tăng tốc không?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGEqZ-SBQPJ6"
      },
      "source": [
        "Có, vì tập dữ liệu lớn và có nhiều hidden layer nên chạy rất chậm nếu chạy tuần tự."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIDTdXBVkJMY"
      },
      "source": [
        "## **Ứng dụng này có thể tăng tốc bằng cách song song hóa không?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FceMbcGxQRJA"
      },
      "source": [
        "Có, vì trong đó có phép convolution, phép nhân ma trận, phép max-pooling,..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J40nxE6n6cF"
      },
      "source": [
        "# **2. Cài đặt tuần tự**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9olwPFlijKzE"
      },
      "source": [
        "## **Thiết kế**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hi6oN-PPhla"
      },
      "source": [
        "*   Trộn ngẫu nhiên thứ tự ảnh.\n",
        "\n",
        "*   Đối với mỗi bức ảnh đầu vào, ta sẽ chuyển nó về mảng numpy.\n",
        "\n",
        "*   Nếu là ảnh RGB thì ta sẽ chuyển nó về ảnh grayscale.\n",
        "\n",
        "*   Tập ảnh sẽ được chia thành nhiều batch có kích thước giống nhau và lớn hơn hoặc bằng 1, batch cuối cùng có thể có kích thước khác.\n",
        "\n",
        "*   Với mỗi batch được đưa vào, ta sẽ chuẩn hoá các mảng numpy trong batch về khoảng [-0.5,0.5] để tránh việc giá trị các lớp sau trở nên quá lớn.\n",
        "\n",
        "*   CNN sẽ có 1 tầng convolutional, 1 tầng max-pooling, 1 tầng fully connected và activation là hàm softmax.\n",
        "\n",
        "    *   Tầng convolution dùng để nhận dạng các đặc trưng cụ thể hoặc hình mẫu trong bức ảnh.\n",
        "\n",
        "    *   Tầng max-pooling dùng để tập hợp các đặc trưng nhỏ lẻ của ảnh thành một đặc trưng lớn hơn, ít nhạy cảm với vị trí của đặc trưng hơn.\n",
        "\n",
        "    *   Tầng fully connected dùng để quyết định nhãn của ảnh.\n",
        "\n",
        "    ![](https://victorzhou.com/media/cnn-post/cnn-dims-3.svg)\n",
        "\n",
        "    <center><small>Nguồn: https://victorzhou.com/blog/intro-to-cnns-part-1/</small></center>\n",
        "\n",
        "*   **Lan truyền xuôi:**\n",
        "\n",
        "    *   ***Tầng convolution:***\n",
        "\n",
        "        Trong tầng này, ta sẽ có $n$ node tương đương với $n$ filter với kích thước là $m$x$m$, trọng số của các filter này sẽ được khởi tạo ngẫu nhiên và mỗi trọng số đó sẽ được chia cho $m$x$m$ để chống việc kết quả ra số quá lớn.\n",
        "\n",
        "        Ta sẽ lần lượt trượt các filter từ phải sang trái, từ trên xuống dưới, mỗi lần một pixel. Với mỗi pixel tương ứng trong cửa sổ trượt, ta sẽ nhân giá trị của nó với trọng số trong filter rồi cộng lại với nhau.\n",
        "\n",
        "        ![](https://drive.google.com/uc?export=view&id=1riGOZlVlZdE-iAId6b23kaMLz7NncRT-)\n",
        "\n",
        "        ![](https://drive.google.com/uc?export=view&id=1M7zZWBg4Hr_aJ7OJZ1t_Y4s48DuYUSkq)\n",
        "\n",
        "    *   ***Tầng max-pooling:***\n",
        "\n",
        "        Với pool có kích thước là $p$x$p$, ta cũng lần lượt trượt các filter từ phải sang trái, từ trên xuống dưới, nhưng mỗi lần là $p$ pixel. Ta sẽ chọn ra giá trị lớn nhất trong cửa sổ trượt đó.\n",
        "\n",
        "        ![](https://drive.google.com/uc?export=view&id=1soCPEqlOsBjZNTap4opnfFF5rehv0anc)\n",
        "\n",
        "    *   ***Tầng fully connected:***\n",
        "\n",
        "        Ta sẽ có $k$ node tương đương với $k$ lớp cần phân, vì đây là tầng fully connected nên tất cả các node của tầng trước sẽ được nối với tất cả các node trong tầng này. Tức là giá trị đầu ra của mỗi node sẽ được tính bằng công thức sau: $t = w * x + b$ với $t$ là giá trị đầu ra của mỗi node, $w$ là vector chứa trọng số của node đó, $x$ là vector các giá trị đầu ra của tất cả các node ở tầng trước đó và $b$ là bias của node đó. Với $k$ node ta sẽ thu được một vector $k$ chiều và ta sẽ tính softmax của vector này, mỗi giá trị sẽ tương ứng với xác suất của mỗi lớp và ta sẽ chọn lớp nào có xác suất cao nhất.\n",
        "\n",
        "        Ta sẽ dùng độ đo cross-entropy để tính độ lỗi: $L=-\\text{ln}(p_c)$ với $p_c$ là xác suất của lớp đúng $c$.\n",
        "\n",
        "*   **Lan truyền ngược:**\n",
        "\n",
        "    Mục tiêu của việc học chỉ đơn giản là tối thiểu hoá độ lỗi. Để làm được điều đó, ta sẽ sử dụng kĩ thuật là Gradient Descent (GD), tức là ta phải tính gradient của hàm lỗi. Ở đây ta sẽ sử dụng một biến thể của GD là Stochastic Gradient Descent (SGD).\n",
        "    SGD cũng giống như GD nhưng thay vì cập nhật các trọng số và bias sau khi duyệt hết tập train, ta sẽ cập nhật với mỗi một batch được duyệt.\n",
        "\n",
        "    Trong quá trình này ta sẽ lần lượt tính các gradient của từng tầng bằng quy tắt mắc xích để cập nhật các trọng số và bias trong các tầng đó.\n",
        "\n",
        "    *   ***Tầng fully connected:***\n",
        "\n",
        "        Ta có thể dùng quy tắc mắc xích để tính các gradient sau của mỗi bức ảnh:\n",
        "        \\begin{equation}\n",
        "          \\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial {\\text{output}_\\text{FCL}}} * \\frac{\\partial {\\text{output}_\\text{FCL}}}{\\partial t} * \\frac{\\partial t}{\\partial w}\n",
        "        \\end{equation}\n",
        "        \\begin{equation}\n",
        "          \\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial {\\text{output}_\\text{FCL}}} * \\frac{\\partial {\\text{output}_\\text{FCL}}}{\\partial t} * \\frac{\\partial t}{\\partial b}\n",
        "        \\end{equation}\n",
        "        \\begin{equation}\n",
        "          \\frac{\\partial L}{\\partial {\\text{output}_\\text{MPL}}} = \\frac{\\partial L}{\\partial {\\text{output}_\\text{FCL}}} * \\frac{\\partial {\\text{output}_\\text{FCL}}}{\\partial t} * \\frac{\\partial t}{\\partial {\\text{output}_\\text{MPL}}}\n",
        "        \\end{equation}\n",
        "\n",
        "        Để tính gradient cho toàn bộ 1 batch, ta tính trung bình cộng các gradient của tất cả các ảnh có trong batch đó.\n",
        "\n",
        "        Sau đó, ta sẽ cập nhật các trọng số sau mỗi một batch được duyệt: $w_i = w_i - \\alpha * \\frac{\\partial L}{\\partial w}$ với $w_i$ là trọng số thứ $i$ và $\\alpha$ là hệ số học.\n",
        "\n",
        "        Tương tự, ta cũng cập nhật các bias: $b_i = b_i - \\alpha * \\frac{\\partial L}{\\partial b}$ với $b_i$ là bias thứ $i$ và $\\alpha$ là hệ số học.\n",
        "\n",
        "        Cuối cùng ta truyền $\\frac{\\partial L}{\\partial {\\text{output}_\\text{MPL}}}$ về cho tầng max-pooling.\n",
        "\n",
        "        Chi tiết các công thức có trong tài liệu tham khảo [2].\n",
        "\n",
        "    *   ***Tầng max-pooling:***\n",
        "\n",
        "        Vì tầng này không có trọng số nên ta không cần cập nhật gì cả. Ta chỉ cần khôi phục lại kích thước ban đầu của mảng trước khi đi qua tầng max-pooling, rồi gán $\\frac{\\partial L}{\\partial {\\text{output}_\\text{MPL}}}$ vào vị trí có giá trị lớn nhất trong cửa sổ trượt $p$x$p$ ban đầu, những vị trí còn lại sẽ được gán bằng 0. Đây chính là $\\frac{\\partial L}{\\partial {\\text{output}_\\text{CL}}}$.\n",
        "\n",
        "        ![](https://victorzhou.com/media/cnn-post/maxpool-backprop.svg)\n",
        "\n",
        "        <center><small>Nguồn: https://victorzhou.com/blog/intro-to-cnns-part-2/</small></center>\n",
        "\n",
        "        Ta sẽ truyền $\\frac{\\partial L}{\\partial {\\text{output}_\\text{CL}}}$ về cho tầng convolution.\n",
        "\n",
        "        Việc này được thực hiện độc lập nhau với tất cả các ảnh có trong 1 batch.\n",
        "\n",
        "    *   ***Tầng convolutional:***\n",
        "\n",
        "        Ta cũng dùng quy tắc mắc xích để tính gradient sau:\n",
        "        \\begin{equation}\n",
        "          \\frac{\\partial L}{\\partial \\text{filter}(x,y)} = \\sum\\limits_{i}\\sum\\limits_{j}\\frac{\\partial L}{\\partial {\\text{output}_\\text{CL}(i,j)}} * \\frac{\\partial {\\text{output}_\\text{CL}(i,j)}}{\\partial \\text{filter}(x,y)}\n",
        "        \\end{equation}\n",
        "\n",
        "        Tương tự, để tính gradient cho toàn bộ 1 batch, ta tính trung bình cộng các gradient của tất cả các ảnh có trong batch đó.\n",
        "\n",
        "        Ta cập nhật các trọng số của filter: $\\text{filter}(x,y) = \\text{filter}(x,y) - \\alpha * \\frac{\\partial L}{\\partial \\text{filter}(x,y)}$ với $\\text{filter}(x,y)$ là trọng số của filter ở dòng $x$ cột $y$ và $\\alpha$ là hệ số học.\n",
        "\n",
        "        Chi tiết các công thức có trong tài liệu tham khảo [2].\n",
        "\n",
        "*   Lặp lại cho tất cả các ảnh còn lại.\n",
        "    \n",
        "*   Nếu đã duyệt hết ảnh, ta sẽ thực hiện lại từ đầu, 1 vòng như vậy được gọi là 1 epoch.\n",
        "\n",
        "*   Sau khi thực hiện tất cả các epoch, ta sẽ thu được một mô hình với các trọng số đã được cập nhật."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCCDXDfrjOn6"
      },
      "source": [
        "## **Đánh giá**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-1mGURnjWKE"
      },
      "source": [
        "### **Cấu hình**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8pcWtQEQDIA"
      },
      "source": [
        "*   Thử nghiệm trên tập dữ liệu chữ số viết tay MNIST. Tập dữ liệu này chứa các ảnh chữ số viết tay từ 0 đến 9, nó bao gồm 60000 ảnh trong tập train và 10000 ảnh trong tập test, mỗi ảnh có kích thước là 28x28 và là ảnh grayscale.\n",
        "\n",
        "*   Cấu hình của CNN như sau:\n",
        "\n",
        "  *   Tầng convolutional sẽ có 32 filter, mỗi filter sẽ có kích thước là 5x5.\n",
        "\n",
        "  *   Tầng max pool có kích thước của pool là 2x2.\n",
        "\n",
        "  *   Tầng fully connected sẽ có 10 node tương ứng với 10 chữ số từ 0 đến 9.\n",
        "\n",
        "  *   $\\alpha = 0.005$\n",
        "\n",
        "  *   epoch = 10\n",
        "\n",
        "  *   batch size = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht4dsFtijcSK"
      },
      "source": [
        "### **Nhận xét**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilKZnRvMjlA3"
      },
      "source": [
        "  *   Thời gian huấn luyện khoảng 16 phút 22 giây cho 10 epoch với mỗi epoch khoảng 98 giây. Tỷ lệ chính xác khi train đạt khoảng 90% và tỷ lệ chính xác khi test đạt khoảng 91%.\n",
        "\n",
        "  *   Thời gian huấn luyện của keras nhanh hơn, chỉ 3 phút 40 giây cho 10 epoch với mỗi epoch khoảng 22 giây. Tỷ lệ chính xác khi train đạt khoảng 92% và tỷ lệ chính xác khi test cũng đạt khoảng 92%.\n",
        "\n",
        "  *   Nhóm vẫn chưa biết tại sao lại có sự khác biệt này."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDfSkDL6jZUu"
      },
      "source": [
        "### **Kết quả**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlSzKzmMJVof",
        "outputId": "de7aafc5-ef3b-40b8-8fd9-e0dc2c6f5133"
      },
      "source": [
        "!python source.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-23 06:11:05.257866: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Loading data...\n",
            "Normalizing...\n",
            "Initiating parameters...\n",
            "Compiling...\n",
            "\n",
            "--------------Our model--------------\n",
            "\n",
            "Epoch 1/10\n",
            "\t98s - loss: 0.4297 - accuracy: 0.8779 - val_loss: 0.3730 - val_accuracy: 0.8916\n",
            "Epoch 2/10\n",
            "\t98s - loss: 0.3769 - accuracy: 0.8897 - val_loss: 0.3419 - val_accuracy: 0.9007\n",
            "Epoch 3/10\n",
            "\t98s - loss: 0.3557 - accuracy: 0.8957 - val_loss: 0.3245 - val_accuracy: 0.9068\n",
            "Epoch 4/10\n",
            "\t98s - loss: 0.3438 - accuracy: 0.8987 - val_loss: 0.3183 - val_accuracy: 0.9086\n",
            "Epoch 5/10\n",
            "\t98s - loss: 0.3357 - accuracy: 0.9017 - val_loss: 0.3143 - val_accuracy: 0.9099\n",
            "Epoch 6/10\n",
            "\t97s - loss: 0.3293 - accuracy: 0.9023 - val_loss: 0.3077 - val_accuracy: 0.9121\n",
            "Epoch 7/10\n",
            "\t97s - loss: 0.3241 - accuracy: 0.9051 - val_loss: 0.3056 - val_accuracy: 0.9127\n",
            "Epoch 8/10\n",
            "\t98s - loss: 0.3198 - accuracy: 0.9061 - val_loss: 0.2993 - val_accuracy: 0.9138\n",
            "Epoch 9/10\n",
            "\t98s - loss: 0.3165 - accuracy: 0.9081 - val_loss: 0.2991 - val_accuracy: 0.9127\n",
            "Epoch 10/10\n",
            "\t97s - loss: 0.3139 - accuracy: 0.9073 - val_loss: 0.2955 - val_accuracy: 0.9131\n",
            "Total runtime: 00:16:22\n",
            "\n",
            "--------------Keras model--------------\n",
            "\n",
            "2021-06-23 06:29:26.224332: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-06-23 06:29:26.235590: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-06-23 06:29:26.235648: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (8a7a3f6b434b): /proc/driver/nvidia/version does not exist\n",
            "2021-06-23 06:29:26.597584: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-06-23 06:29:26.598154: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2299995000 Hz\n",
            "Epoch 1/10\n",
            "600/600 - 23s - loss: 1.1142 - accuracy: 0.7173 - val_loss: 0.4898 - val_accuracy: 0.8702\n",
            "Epoch 2/10\n",
            "600/600 - 22s - loss: 0.4335 - accuracy: 0.8794 - val_loss: 0.3650 - val_accuracy: 0.8961\n",
            "Epoch 3/10\n",
            "600/600 - 22s - loss: 0.3666 - accuracy: 0.8936 - val_loss: 0.3327 - val_accuracy: 0.9054\n",
            "Epoch 4/10\n",
            "600/600 - 22s - loss: 0.3388 - accuracy: 0.9014 - val_loss: 0.3135 - val_accuracy: 0.9104\n",
            "Epoch 5/10\n",
            "600/600 - 22s - loss: 0.3223 - accuracy: 0.9058 - val_loss: 0.2961 - val_accuracy: 0.9168\n",
            "Epoch 6/10\n",
            "600/600 - 22s - loss: 0.3098 - accuracy: 0.9105 - val_loss: 0.2877 - val_accuracy: 0.9183\n",
            "Epoch 7/10\n",
            "600/600 - 22s - loss: 0.2993 - accuracy: 0.9131 - val_loss: 0.2778 - val_accuracy: 0.9216\n",
            "Epoch 8/10\n",
            "600/600 - 22s - loss: 0.2906 - accuracy: 0.9158 - val_loss: 0.2752 - val_accuracy: 0.9219\n",
            "Epoch 9/10\n",
            "600/600 - 22s - loss: 0.2821 - accuracy: 0.9183 - val_loss: 0.2637 - val_accuracy: 0.9247\n",
            "Epoch 10/10\n",
            "600/600 - 22s - loss: 0.2742 - accuracy: 0.9207 - val_loss: 0.2579 - val_accuracy: 0.9263\n",
            "Total runtime: 00:03:40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTnEOJceMiNC"
      },
      "source": [
        "# **3. Cài đặt song song (trên GPU)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjTNfOIdN1aS"
      },
      "source": [
        "## **Phân tích**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRqt7CYzj5mX"
      },
      "source": [
        "Các phép convolution, max-pooling và nhân ma trận chiếm nhiều thời gian thực thi nhất và các phép toán trong đó hoàn toàn độc lập với nhau nên ta có thể song song hoá 3 thao tác này."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgbwhjHFj77n"
      },
      "source": [
        "##**Thiết kế**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S3JMJlyOAmq"
      },
      "source": [
        "Tránh việc phải di chuyển dữ liệu qua lại giữa CPU và GPU nhiều nhất có thể.\n",
        "\n",
        "Đối với phép nhân ma trận, ta sẽ sử dụng block 2 chiều và grid 2 chiều, với mỗi thread sẽ tính một phần tử trong ma trận output.\n",
        "\n",
        "Đối với phép convolution và max-pooling, ta sẽ sử dụng block 2 chiều và grid 3 chiều, với mỗi thread sẽ tính một phần tử trong ma trận output và chiều z của grid sẽ ứng với mỗi neuron.\n",
        "\n",
        "Mỗi hàm kernel sẽ chỉ xử lý đúng 1 ảnh được đưa vào."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSVJ9Z61Ret6"
      },
      "source": [
        "## **Đánh giá**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXvZAQOJh0j7"
      },
      "source": [
        "### **Cấu hình**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6x5WC6bg-wC"
      },
      "source": [
        "*   Thử nghiệm trên tập dữ liệu chữ số viết tay MNIST. Tập dữ liệu này chứa các ảnh chữ số viết tay từ 0 đến 9, nó bao gồm 60000 ảnh trong tập train và 10000 ảnh trong tập test, mỗi ảnh có kích thước là 28x28 và là ảnh grayscale.\n",
        "\n",
        "*   Cấu hình của CNN như sau:\n",
        "\n",
        "  *   Tầng convolutional sẽ có 32 filter, mỗi filter sẽ có kích thước là 5x5.\n",
        "\n",
        "  *   Tầng max pool có kích thước của pool là 2x2.\n",
        "\n",
        "  *   Tầng fully connected sẽ có 10 node tương ứng với 10 chữ số từ 0 đến 9.\n",
        "\n",
        "  *   $\\alpha = 0.005$\n",
        "\n",
        "  *   epoch = 10\n",
        "\n",
        "  *   batch size = 100\n",
        "\n",
        "  *   **block size = (32, 32)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-Cnm_dOiKiD"
      },
      "source": [
        "### **Nhận xét**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyUjbHMvhEuC"
      },
      "source": [
        "Mặc dù chương trình chạy đúng nhưng thời gian thực thi không được rút ngắn như mong đợi, thậm chí còn chậm hơn rất nhiều lần so với host, với tổng thời gian thực thi là 1 tiếng 3 phút 40 giây, mỗi epoch chiếm khoảng 382 giây.\n",
        "\n",
        "Việc này là do vòng lặp của python quá chậm, ta cũng không thể jit được hàm gọi hàm kernel nên ta sẽ cần một thiết kế khác hiệu quả hơn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUonWD1uh_QS"
      },
      "source": [
        "### **Kết quả**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4Fpmx0UTJ5a",
        "outputId": "d828f782-142c-4b16-e4b3-bfd25dcb4df9"
      },
      "source": [
        "!python source_cuda_ver_1.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-03 05:02:19.841767: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Loading data...\n",
            "Shuffle training data\n",
            "Normalizing and copying data to GPU...\n",
            "Initiating parameters...\n",
            "Start training...\n",
            "\n",
            "--------------Our model--------------\n",
            "\n",
            "Epoch 1/10\n",
            "\t385s - loss: 0.9879 - accuracy: 0.7543 - val_loss: 0.4640 - val_accuracy: 0.8780\n",
            "Epoch 2/10\n",
            "\t382s - loss: 0.4274 - accuracy: 0.8784 - val_loss: 0.3688 - val_accuracy: 0.8954\n",
            "Epoch 3/10\n",
            "\t382s - loss: 0.3754 - accuracy: 0.8899 - val_loss: 0.3399 - val_accuracy: 0.9036\n",
            "Epoch 4/10\n",
            "\t381s - loss: 0.3546 - accuracy: 0.8960 - val_loss: 0.3254 - val_accuracy: 0.9066\n",
            "Epoch 5/10\n",
            "\t382s - loss: 0.3425 - accuracy: 0.8993 - val_loss: 0.3165 - val_accuracy: 0.9095\n",
            "Epoch 6/10\n",
            "\t381s - loss: 0.3342 - accuracy: 0.9013 - val_loss: 0.3102 - val_accuracy: 0.9105\n",
            "Epoch 7/10\n",
            "\t381s - loss: 0.3279 - accuracy: 0.9040 - val_loss: 0.3054 - val_accuracy: 0.9113\n",
            "Epoch 8/10\n",
            "\t382s - loss: 0.3228 - accuracy: 0.9056 - val_loss: 0.3015 - val_accuracy: 0.9132\n",
            "Epoch 9/10\n",
            "\t381s - loss: 0.3185 - accuracy: 0.9071 - val_loss: 0.2982 - val_accuracy: 0.9147\n",
            "Epoch 10/10\n",
            "\t381s - loss: 0.3147 - accuracy: 0.9085 - val_loss: 0.2953 - val_accuracy: 0.9148\n",
            "Total runtime: 01:03:40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY6xiR6NMkOC"
      },
      "source": [
        "# **4. Cài đặt song song (trên GPU) + tối ưu hóa**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dniv7VIJ1Lzj"
      },
      "source": [
        "## **4.1. Tối ưu hoá lần 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTza_DH6kQLe"
      },
      "source": [
        "### **Phân tích**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1R6UlwowObB"
      },
      "source": [
        "Vì vòng lặp trong python rất chậm nên ta sẽ đưa vòng lặp đó vào trong hàm kernel, nghĩa là mỗi hàm kernel sẽ xử lý cả 1 batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcNEbdbnkSAh"
      },
      "source": [
        "### **Thiết kế**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgYDyxbRxRQy"
      },
      "source": [
        "Ta chỉ cần thêm 1 vòng lặp vào các hàm kernel như phiên bản đầu để một hàm kernel có thể xử lý nhiều ảnh trong 1 lần gọi và tránh xử dụng vòng lặp của python nhiều nhất có thể.\n",
        "\n",
        "Riêng việc cập nhật các trọng số, ta sẽ sao chép dữ liệu ra CPU rồi mới tiến hành cập nhật, lý do sẽ được nói rõ ở phần sau."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu-4uk1Hyndr"
      },
      "source": [
        "### **Đánh giá**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WecwjxmvifwR"
      },
      "source": [
        "#### **Cấu hình**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDM-l95MiqKm"
      },
      "source": [
        "Các thông số cấu hình đều được giữ nguyên."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOFKsDIlilaD"
      },
      "source": [
        "#### **Nhận xét**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFib1enwisdp"
      },
      "source": [
        "Chỉ cần 1 thay đổi rất đơn giản này mà thời gian thực thi đã giảm đi rất rất nhiều, tổng thời gian thực thi chỉ còn 2 phút 6 giây với mỗi epoch chiếm khoảng 12 giây."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsIa-vmTii28"
      },
      "source": [
        "#### **Kết quả**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7i_GfoKTUyX",
        "outputId": "a47a611e-d682-4d05-acf9-aba44e8361a4"
      },
      "source": [
        "!python source_cuda_ver_2.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-03 06:06:03.959580: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Loading data...\n",
            "Shuffle training data\n",
            "Normalizing and copying data to GPU...\n",
            "Initiating parameters...\n",
            "Start training...\n",
            "\n",
            "--------------Our model--------------\n",
            "\n",
            "Epoch 1/10\n",
            "\t16s - loss: 0.9889 - accuracy: 0.7607 - val_loss: 0.4637 - val_accuracy: 0.8773\n",
            "Epoch 2/10\n",
            "\t12s - loss: 0.4275 - accuracy: 0.8800 - val_loss: 0.3686 - val_accuracy: 0.8942\n",
            "Epoch 3/10\n",
            "\t12s - loss: 0.3749 - accuracy: 0.8907 - val_loss: 0.3396 - val_accuracy: 0.9026\n",
            "Epoch 4/10\n",
            "\t12s - loss: 0.3540 - accuracy: 0.8958 - val_loss: 0.3250 - val_accuracy: 0.9071\n",
            "Epoch 5/10\n",
            "\t12s - loss: 0.3418 - accuracy: 0.8991 - val_loss: 0.3159 - val_accuracy: 0.9097\n",
            "Epoch 6/10\n",
            "\t12s - loss: 0.3334 - accuracy: 0.9019 - val_loss: 0.3094 - val_accuracy: 0.9110\n",
            "Epoch 7/10\n",
            "\t12s - loss: 0.3270 - accuracy: 0.9039 - val_loss: 0.3044 - val_accuracy: 0.9123\n",
            "Epoch 8/10\n",
            "\t12s - loss: 0.3218 - accuracy: 0.9057 - val_loss: 0.3003 - val_accuracy: 0.9133\n",
            "Epoch 9/10\n",
            "\t12s - loss: 0.3174 - accuracy: 0.9071 - val_loss: 0.2968 - val_accuracy: 0.9134\n",
            "Epoch 10/10\n",
            "\t12s - loss: 0.3135 - accuracy: 0.9085 - val_loss: 0.2937 - val_accuracy: 0.9144\n",
            "Total runtime: 00:02:06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPw-00Sc0crr"
      },
      "source": [
        "### **Lý do cho việc không thực hiện cập nhật trong device**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZDCmoW32ttU"
      },
      "source": [
        "Do sự khác biệt về cách tính toán số floating-point nên kết quả khi chạy trên host sẽ khác với kết quả khi chạy trên device. Mặc dù sự khác biệt là rất nhỏ nhưng khi đi qua nhiều lặp thì sự khác biệt này sẽ trở nên rõ rệt và sẽ ảnh hưởng rất lớn đến độ chính xác của chương trình (từ 87% xuống 16%). Ngoài ra ở phiên bản này vì gặp phải hiện tượng tràn số nên phải giảm learningRate xuống = 0.0001.\n",
        "\n",
        "Mặc dù ở phiên bản dưới đây có thời gian thực thi nhanh hơn phiên bản trên 2 giây nhưng việc này là không đáng kể và tiềm ẩn nhiều lỗi không thể ngờ tới."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD4u9Fq-Tr7s",
        "outputId": "c5c5ad99-150b-441f-806a-d7065567deca"
      },
      "source": [
        "!python source_cuda_ver_3.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-03 06:08:13.623291: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Loading data...\n",
            "Shuffle training data\n",
            "Normalizing and copying data to GPU...\n",
            "Initiating parameters...\n",
            "Start training...\n",
            "\n",
            "--------------Our model--------------\n",
            "\n",
            "Epoch 1/10\n",
            "\t14s - loss: 2.3025 - accuracy: 0.1058 - val_loss: 2.2297 - val_accuracy: 0.1637\n",
            "Epoch 2/10\n",
            "\t10s - loss: 2.2309 - accuracy: 0.1596 - val_loss: 2.1658 - val_accuracy: 0.2849\n",
            "Epoch 3/10\n",
            "\t10s - loss: 2.1675 - accuracy: 0.2743 - val_loss: 2.1003 - val_accuracy: 0.4185\n",
            "Epoch 4/10\n",
            "\t10s - loss: 2.1017 - accuracy: 0.4016 - val_loss: 2.0306 - val_accuracy: 0.5141\n",
            "Epoch 5/10\n",
            "\t10s - loss: 2.0315 - accuracy: 0.4922 - val_loss: 1.9555 - val_accuracy: 0.5795\n",
            "Epoch 6/10\n",
            "\t10s - loss: 1.9556 - accuracy: 0.5560 - val_loss: 1.8744 - val_accuracy: 0.6236\n",
            "Epoch 7/10\n",
            "\t10s - loss: 1.8738 - accuracy: 0.6038 - val_loss: 1.7876 - val_accuracy: 0.6580\n",
            "Epoch 8/10\n",
            "\t10s - loss: 1.7864 - accuracy: 0.6391 - val_loss: 1.6962 - val_accuracy: 0.6880\n",
            "Epoch 9/10\n",
            "\t10s - loss: 1.6949 - accuracy: 0.6681 - val_loss: 1.6020 - val_accuracy: 0.7092\n",
            "Epoch 10/10\n",
            "\t10s - loss: 1.6010 - accuracy: 0.6913 - val_loss: 1.5073 - val_accuracy: 0.7289\n",
            "Total runtime: 00:01:52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM3TN_z64ICY"
      },
      "source": [
        "## **4.2. Tối ưu hoá lần 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BewoPgeD4XrJ"
      },
      "source": [
        "### **Phân tích**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gLNWXK9o0Xq"
      },
      "source": [
        "Xét thấy trong hàm convolution layer kernel, mỗi thread đều truy cập cùng một vùng nhớ nhiều lần ở GMEM nên ta có thể tải dữ liệu lên SMEM để giảm thiểu số lần truy cập vào GMEM, từ đó tăng tốc độ tính toán."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx6Y2sSg4VBC"
      },
      "source": [
        "### **Thiết kế**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3p97WQoo21O"
      },
      "source": [
        "Ta thêm biến là mảng dữ liệu gọi trong hàm SMEM sau đó chép dữ liệu từ bên GMEM qua SMEM rồi khi truy xuất dữ liệu cần từ mảng SMEM này trong 2 hàm convolution layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7pIBi3a4bA6"
      },
      "source": [
        "### **Đánh giá**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_5mOU7lorJf"
      },
      "source": [
        "### **Kết quả**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTkXlCxwGR5Q",
        "outputId": "dc103fb7-764a-4452-9586-1a731bdfb134"
      },
      "source": [
        "!python source_cuda_ver_4.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-09 11:50:11.225538: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Shuffle training data\n",
            "Normalizing and copying data to GPU...\n",
            "Initiating parameters...\n",
            "Start training...\n",
            "\n",
            "--------------Our model--------------\n",
            "\n",
            "Epoch 1/10\n",
            "\t16s - loss: 1.4629 - accuracy: 0.6874 - val_loss: 1.0031 - val_accuracy: 0.8088\n",
            "Epoch 2/10\n",
            "\t12s - loss: 0.8625 - accuracy: 0.8121 - val_loss: 0.7129 - val_accuracy: 0.8416\n",
            "Epoch 3/10\n",
            "\t12s - loss: 0.6715 - accuracy: 0.8386 - val_loss: 0.5911 - val_accuracy: 0.8559\n",
            "Epoch 4/10\n",
            "\t12s - loss: 0.5810 - accuracy: 0.8528 - val_loss: 0.5266 - val_accuracy: 0.8657\n",
            "Epoch 5/10\n",
            "\t12s - loss: 0.5295 - accuracy: 0.8615 - val_loss: 0.4874 - val_accuracy: 0.8726\n",
            "Epoch 6/10\n",
            "\t12s - loss: 0.4970 - accuracy: 0.8678 - val_loss: 0.4617 - val_accuracy: 0.8770\n",
            "Epoch 7/10\n",
            "\t12s - loss: 0.4749 - accuracy: 0.8722 - val_loss: 0.4435 - val_accuracy: 0.8800\n",
            "Epoch 8/10\n",
            "\t12s - loss: 0.4591 - accuracy: 0.8754 - val_loss: 0.4302 - val_accuracy: 0.8825\n",
            "Epoch 9/10\n",
            "\t12s - loss: 0.4474 - accuracy: 0.8780 - val_loss: 0.4204 - val_accuracy: 0.8853\n",
            "Epoch 10/10\n",
            "\t12s - loss: 0.4386 - accuracy: 0.8799 - val_loss: 0.4127 - val_accuracy: 0.8876\n",
            "Total runtime: 00:02:09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt9Vym-5Mnpi"
      },
      "source": [
        "# **5. Nhìn lại quá trình làm đồ án**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOqVtBhnkYS8"
      },
      "source": [
        "## **Đã gặp những khó khăn gì**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47e6b7uF55cb"
      },
      "source": [
        "*   Lương Bội Sương: phải làm quen với các cú pháp của ngôn ngữ mới và thường gặp những lỗi không rõ ràng hoặc đôi khi còn gây nhầm lẫn nên thường đi vào bế tắc.\n",
        "*   Phạm Như Quyền: lúc đầu còn bỡ ngỡ khi làm quen với thư viện numba và tìm hiểu về các cấu trúc mạng trong đồ án.\n",
        "*   Trần Đình Sang: Giai đoạn đầu do chưa có nền tảng về thư viện và ngôn ngữ nên chậm hơn so với nhịp độ chung của cả nhóm cũng như là trong lớp. \n",
        "*   Võ Thế Sơn: việc làm quen với python giai đoạn đầu mất khá nhiều thời gian, các lỗi trong quá trình code mất nhiều thời gian để sửa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HrtDh5ukayv"
      },
      "source": [
        "## **Học được những gì hữu ích**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7T3--x56ACd"
      },
      "source": [
        "*   Lương Bội Sương: không nên hấp tấp, phải đi từ đơn giản đến phức tạp. Phải có những khoảng nghỉ ngắn để đầu óc được thư giản mới có thể nghĩ ra được ý tưởng mới. Cuối cùng là nhờ đến sự giúp đỡ của người khác khi cần.\n",
        "*   Phạm Như Quyền: đã hiểu được cách sử dụng thư viện và hiểu thêm được quá trình xử lý song song trong một đồ án lớn. Luôn cố gắng phối hợp với các thành viên trong nhóm khi cần.\n",
        "*   Trần Đình Sang: cách chia công việc ra thành nhiều phần và nhiều giai đoạn để dễ thực hiện và tận dụng được lợi thế làm việc nhóm, bên cạnh đó cần có những bước nhìn lại cũng như là thay đổi hướng đi khi cần. \n",
        "*   Võ Thế Sơn: biết được cách song song hoá cơ bản sử dụng ngôn ngữ python, cũng cố thêm kiến thức về lập trình song song trên GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrdRwqgRkdad"
      },
      "source": [
        "## **Nếu có thên thời gian thì nhóm sẽ làm gì**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DOGQOv76Epe"
      },
      "source": [
        "Nhóm sẽ nghiên cứu thêm về mã nguồn của keras để có kết quả giống nhau hơn, tìm hiểu nhiều hơn về kĩ thuật trong học sâu và cấu trúc của CNN để đạt được độ chính xác cao hơn.\n",
        "\n",
        "Tìm cách đưa vào STREAM và hoàn thiện phiên bản sử dụng SMEM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZuhUS07kgPI"
      },
      "source": [
        "# **6. Tài liệu tham khảo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-zg6xzbLTeU"
      },
      "source": [
        "[1] https://victorzhou.com/blog/intro-to-cnns-part-1/\n",
        "\n",
        "[2] https://victorzhou.com/blog/intro-to-cnns-part-2/\n",
        "\n",
        "[3] https://www.kaggle.com/moltean/fruits"
      ]
    }
  ]
}