{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "newReport_06th5 (2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1Ct8kRnL8KT"
      },
      "source": [
        "# **1. Mô tả ứng dụng** \n",
        "\n",
        "*   **Ứng dụng mà nhóm chọn:** Huấn luyện Convolutional Neural Network để phân lớp ảnh bằng Stochastic Gradient Descent.\n",
        "   *   **Input:** Tập dữ liệu ảnh và nhãn của ảnh.\n",
        "\n",
        "   *   **Output:** Mô hình phân lớp ảnh sau khi huấn luyện.\n",
        "\n",
        "   *   **Ý nghĩa của ứng dụng trong thực tế:** Giúp số hoá tài liệu, OCR...\n",
        "\n",
        "*   **Ứng dụng này có cần phải tăng tốc không:** Có, vì tập dữ liệu lớn và có nhiều hidden layer nên chạy rất chậm nếu chạy tuần tự.\n",
        "\n",
        "*   **Ứng dụng này có thể tăng tốc bằng cách song song hóa không**: Có, vì trong đó có phép convolution, phép nhân ma trận, phép max-pooling,..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J40nxE6n6cF"
      },
      "source": [
        "# **2. Cài đặt tuần tự**\n",
        "\n",
        "*   **Thiết kế:**\n",
        "\n",
        "    *   Đối với mỗi bức ảnh đầu vào ta sẽ chuyển nó về mảng numpy.\n",
        "\n",
        "    *   Nếu là ảnh RGB thì ta sẽ chuyển nó về ảnh grayscale.\n",
        "\n",
        "    *   Trước khi đưa vào CNN ta sẽ chuẩn hoá mảng numpy trên về khoảng [-0.5,0.5] để tránh việc giá trị cách lớp sau trở nên quá lớn.\n",
        "\n",
        "    *   CNN sẽ có 1 convolutional layer, 1 max-pooling layer, 1 fully connected layer và activation là hàm softmax.\n",
        "        ![](https://victorzhou.com/media/cnn-post/cnn-dims-3.svg)\n",
        "        <center><small>Nguồn: https://victorzhou.com/blog/intro-to-cnns-part-1/</small></center>\n",
        "\n",
        "    *   **Lan truyền xuôi:**\n",
        "\n",
        "        Quá trình này chính là cách mà CNN cho ra kết quả dự đoán.\n",
        "\n",
        "        *   ***Convolutional layer:***\n",
        "\n",
        "            Trong layer này, ta sẽ có $n$ node tương đương với $n$ filter với kích thước là $m$x$m$, trọng số của các filter này sẽ được khởi tạo ngẫu nhiên và mỗi trọng số đó sẽ được chia cho $m$x$m$ để chống việc kết quả ra số quá lớn.\n",
        "\n",
        "            Ta sẽ lần lượt trượt các filter từ phải sang trái, từ trên xuống dưới, mỗi lần một pixel. Với mỗi pixel tương ứng trong cửa sổ trượt, ta sẽ nhân giá trị của nó với trọng số trong filter rồi cộng lại với nhau.\n",
        "\n",
        "            ![](https://victorzhou.com/media/cnn-post/convolve-example-2.svg)\n",
        "        \n",
        "            <center><small>Nguồn: https://victorzhou.com/blog/intro-to-cnns-part-1/</small></center>\n",
        "\n",
        "            ![](https://victorzhou.com/69b4c1dd078ee363317bb8fa323eaace/convolve-output.gif)\n",
        "\n",
        "            <center><small>Nguồn: https://victorzhou.com/blog/intro-to-cnns-part-1/</small></center>\n",
        "\n",
        "        *   ***Max pool layer:***\n",
        "\n",
        "            Với pool có kích thước là $p$x$p$, ta cũng lần lượt trượt các filter từ phải sang trái, từ trên xuống dưới, nhưng mỗi lần là $p$ pixel. Ta sẽ chọn ra giá trị lớn nhất trong cửa sổ trượt đó.\n",
        "\n",
        "            Phép max pooling sẽ giúp ta làm giảm đi kích thước của ảnh $p$ lần nhưng vẫn giữ lại được những thông tin quan trọng.\n",
        "\n",
        "            ![](https://victorzhou.com/ac441205fd06dc037b3db2dbf05660f7/pool.gif)\n",
        "\n",
        "            <center><small>Nguồn: https://victorzhou.com/blog/intro-to-cnns-part-1/</small></center>\n",
        "\n",
        "        *   ***Fully connected layer:***\n",
        "\n",
        "            Ta sẽ có $k$ node tương đương với $k$ lớp cần phân, vì đây là fully connected layer nên tất cả các node của layer trước sẽ được nối với tất cả các node trong layer này. Tức là giá trị đầu ra của mỗi node sẽ được tính bằng công thức sau: $t = w * x + b$ với $t$ là giá trị đầu ra của mỗi node, $w$ là vector chứa trọng số của node đó, $x$ là vector các giá trị đầu ra của tất cả các node ở layer trước đó và $b$ là bias của node đó. Với $k$ node ta sẽ thu được một vector $k$ chiều và ta sẽ tính softmax của vector này, mỗi giá trị sẽ tương ứng với xác suất của mỗi lớp và ta sẽ chọn lớp nào có xác suất cao nhất.\n",
        "\n",
        "    *   **Lan truyền ngược:**\n",
        "\n",
        "        Trong quá trình này ta sẽ lần lượt tính các gradient của từng layer bằng quy tắt mắc xích để cập nhật các trọng số và bias trong các layer đó.\n",
        "\n",
        "        *   ***Fully connected layer:***\n",
        "\n",
        "            Ta sẽ dùng độ đo cross-entropy để tính độ lỗi: $L=-\\text{ln}(p_c)$ với $p_c$ là xác suất của lớp đúng $c$.\n",
        "\n",
        "            Ta có thể dùng quy tắc mắc xích để tính các gradient sau:\n",
        "            \\begin{equation}\n",
        "              \\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial {\\text{output}_\\text{FCL}}} * \\frac{\\partial {\\text{output}_\\text{FCL}}}{\\partial t} * \\frac{\\partial t}{\\partial w}\n",
        "            \\end{equation}\n",
        "            \\begin{equation}\n",
        "              \\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial {\\text{output}_\\text{FCL}}} * \\frac{\\partial {\\text{output}_\\text{FCL}}}{\\partial t} * \\frac{\\partial t}{\\partial b}\n",
        "            \\end{equation}\n",
        "            \\begin{equation}\n",
        "              \\frac{\\partial L}{\\partial {\\text{output}_\\text{MPL}}} = \\frac{\\partial L}{\\partial {\\text{output}_\\text{FCL}}} * \\frac{\\partial {\\text{output}_\\text{FCL}}}{\\partial t} * \\frac{\\partial t}{\\partial {\\text{output}_\\text{MPL}}}\n",
        "            \\end{equation}\n",
        "\n",
        "            Sau đó ta cập nhật các trọng số: $w_i = w_i - \\alpha * \\frac{\\partial L}{\\partial w}$ với $w_i$ là trọng số thứ $i$ và $\\alpha$ là hệ số học.\n",
        "\n",
        "            Tương tự, ta cũng cập nhật các bias: $b_i = b_i - \\alpha * \\frac{\\partial L}{\\partial b}$ với $b_i$ là bias thứ $i$ và $\\alpha$ là hệ số học.\n",
        "\n",
        "            Cuối cùng ta truyền $\\frac{\\partial L}{\\partial {\\text{output}_\\text{MPL}}}$ về cho max pool layer.\n",
        "\n",
        "            Chi tiết các công thức có trong tài liệu tham khảo [2].\n",
        "\n",
        "        *   ***Max pool layer:***\n",
        "\n",
        "            Vì layer này không có trọng số nên ta không cần cập nhật gì cả. Ta chỉ cần khôi phục lại kích thước ban đầu trước khi đi qua max pool layer, rồi gán $\\frac{\\partial L}{\\partial {\\text{output}_\\text{MPL}}}$ vào vị trí có giá trị lớn nhất trong cửa sổ trượt $p$x$p$ ban đầu, những vị trí còn lại sẽ được gán bằng 0. Đây chính là $\\frac{\\partial L}{\\partial {\\text{output}_\\text{CL}}}$.\n",
        "\n",
        "            ![](https://victorzhou.com/media/cnn-post/maxpool-backprop.svg)\n",
        "\n",
        "            <center><small>Nguồn: https://victorzhou.com/blog/intro-to-cnns-part-2/</small></center>\n",
        "\n",
        "            Ta sẽ truyền $\\frac{\\partial L}{\\partial {\\text{output}_\\text{CL}}}$ về cho convolutional layer.\n",
        "\n",
        "        *   ***Convolutional layer:***\n",
        "\n",
        "            Ta cũng dùng quy tắc mắc xích để tính gradient sau:\n",
        "            \\begin{equation}\n",
        "              \\frac{\\partial L}{\\partial \\text{filter}(x,y)} = \\sum\\limits_{i}\\sum\\limits_{j}\\frac{\\partial L}{\\partial {\\text{output}_\\text{CL}(i,j)}} * \\frac{\\partial {\\text{output}_\\text{CL}(i,j)}}{\\partial \\text{filter}(x,y)}\n",
        "            \\end{equation}\n",
        "\n",
        "            Ta cập nhật các trọng số của filter: $\\text{filter}(x,y) = \\text{filter}(x,y) - \\alpha * \\frac{\\partial L}{\\partial \\text{filter}(x,y)}$ với $\\text{filter}(x,y)$ là trọng số của filter ở dòng $x$ cột $y$ và $\\alpha$ là hệ số học.\n",
        "\n",
        "            Chi tiết các công thức có trong tài liệu tham khảo [2].\n",
        "\n",
        "    *   Lập lại cho tất cả các ảnh trong tập dữ liệu.\n",
        "    \n",
        "*   **Đánh giá:**\n",
        "\n",
        "    *   **Tập ảnh chữ số viết tay MNIST:**\n",
        "\n",
        "        *   Tập dữ liệu này chứa các ảnh chữ số viết tay từ 0 đến 9, nó bao gồm 60000 ảnh trong tập train và 10000 ảnh trong tập test, mỗi ảnh có kích thước là 28x28 và là ảnh grayscale.\n",
        "\n",
        "        *   Cấu hình của CNN như sau:\n",
        "\n",
        "            *   Convolutional layer sẽ có 8 filter, mỗi filter sẽ có kích thước là 3x3.\n",
        "\n",
        "            *   Max pool layer có kích thước của pool là 2x2.\n",
        "\n",
        "            *   Fully connected layer sẽ có 10 node tương ứng với 10 chữ số từ 0 đến 9.\n",
        "\n",
        "            *   $\\alpha = 0.005$\n",
        "\n",
        "        *   Kết quả: thời gian huấn luyện tương đối nhanh, chỉ mất khoảng 90 giây. Độ chính xác khi huấn luyện đạt được khoảng 92%. Độ chính xác khi test đạt được khoảng 95%.\n",
        "\n",
        "    *   **Tập ảnh hoa quả \"Fruits 360\" [3]:**\n",
        "\n",
        "        *   Tập dữ liệu này chứa 131 loại hoa quả khác nhau, được chụp với các góc khác nhau, nó bao gồm 67692 ảnh trong tập train và 22688 ảnh trong tập test, mỗi ảnh có kích thước là 100x100 và là ảnh RGB.\n",
        "\n",
        "        *   Cấu hình của CNN như sau:\n",
        "\n",
        "            *   Convolutional layer sẽ có 1 filter với kích thước là 7x7.\n",
        "\n",
        "            *   Max pool layer có kích thước của pool là 3x3.\n",
        "\n",
        "            *   Fully connected layer sẽ có 131 node.\n",
        "\n",
        "            *   $\\alpha = 0.005$\n",
        "\n",
        "        *   Kết quả:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95UQoS3VINxf"
      },
      "source": [
        "!python \"/content/drive/MyDrive/LTSSUD/source_fruits.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTnEOJceMiNC"
      },
      "source": [
        "# **3. Cài đặt song song (trên GPU)**\n",
        "\n",
        "*   **Phân tích:**\n",
        "*   **Thiết kế:**\n",
        "*   **Đánh giá:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY6xiR6NMkOC"
      },
      "source": [
        "# **4. Cài đặt song song (trên GPU) + tối ưu hóa**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt9Vym-5Mnpi"
      },
      "source": [
        "# **5. Nhìn lại quá trình làm đồ án**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-zg6xzbLTeU"
      },
      "source": [
        "# **6. Tài liệu tham khảo**\n",
        "\n",
        "[1] https://victorzhou.com/blog/intro-to-cnns-part-1/\n",
        "\n",
        "[2] https://victorzhou.com/blog/intro-to-cnns-part-2/\n",
        "\n",
        "[3] https://www.kaggle.com/moltean/fruits"
      ]
    }
  ]
}