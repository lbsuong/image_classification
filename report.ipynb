{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "report.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1Ct8kRnL8KT"
      },
      "source": [
        "# **1. Mô tả ứng dụng** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxpYMlTEQMwf"
      },
      "source": [
        "## **Ứng dụng mà nhóm chọn**\n",
        "Huấn luyện Convolutional Neural Network để phân lớp ảnh bằng Stochastic Gradient Descent.\n",
        "*   **Input:** Tập dữ liệu ảnh và nhãn của ảnh, cấu trúc của CNN và các tham số liên quan.\n",
        "\n",
        "*   **Output:** Mô hình phân lớp ảnh sau khi huấn luyện.\n",
        "\n",
        "*   **Ý nghĩa của ứng dụng trong thực tế:** Giúp số hoá tài liệu, OCR..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGEqZ-SBQPJ6"
      },
      "source": [
        "## **Ứng dụng này có cần phải tăng tốc không**\n",
        "Có, vì tập dữ liệu lớn và có nhiều tầng ẩn nên chạy rất chậm nếu chạy tuần tự."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FceMbcGxQRJA"
      },
      "source": [
        "## **Ứng dụng này có thể tăng tốc bằng cách song song hóa không**\n",
        "Có, vì trong đó có phép convolution, phép nhân ma trận, phép max-pooling,..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J40nxE6n6cF"
      },
      "source": [
        "# **2. Cài đặt tuần tự**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hi6oN-PPhla"
      },
      "source": [
        "## **Thiết kế**\n",
        "\n",
        "*   Trộn ngẫu nhiên thứ tự ảnh.\n",
        "\n",
        "*   Đối với mỗi bức ảnh đầu vào, ta sẽ chuyển nó về mảng numpy.\n",
        "\n",
        "*   Nếu là ảnh RGB thì ta sẽ chuyển nó về ảnh grayscale.\n",
        "\n",
        "*   Tập ảnh sẽ được chia thành nhiều batch có kích thước giống nhau và lớn hơn hoặc bằng 1, batch cuối cùng có thể có kích thước khác.\n",
        "\n",
        "*   Với mỗi batch được đưa vào, ta sẽ chuẩn hoá các mảng numpy trong batch về khoảng [-0.5,0.5] để tránh việc giá trị các lớp sau trở nên quá lớn.\n",
        "\n",
        "*   CNN sẽ có 1 tầng convolutional, 1 tầng max-pooling, 1 tầng fully connected và activation là hàm softmax.\n",
        "\n",
        "    *   Tầng convolution dùng để nhận dạng các đặc trưng cụ thể hoặc hình mẫu trong bức ảnh.\n",
        "\n",
        "    *   Tầng max-pooling dùng để tập hợp các đặc trưng nhỏ lẻ của ảnh thành một đặc trưng lớn hơn, ít nhạy cảm với vị trí của đặc trưng hơn.\n",
        "\n",
        "    *   Tầng fully connected dùng để quyết định nhãn của ảnh.\n",
        "\n",
        "    ![](https://victorzhou.com/media/cnn-post/cnn-dims-3.svg)\n",
        "\n",
        "    <center><small>Nguồn: https://victorzhou.com/blog/intro-to-cnns-part-1/</small></center>\n",
        "\n",
        "*   **Lan truyền xuôi:**\n",
        "\n",
        "    *   ***Tầng convolution:***\n",
        "\n",
        "        Trong tầng này, ta sẽ có $n$ node tương đương với $n$ filter với kích thước là $m$x$m$, trọng số của các filter này sẽ được khởi tạo ngẫu nhiên và mỗi trọng số đó sẽ được chia cho $m$x$m$ để chống việc kết quả ra số quá lớn.\n",
        "\n",
        "        Ta sẽ lần lượt trượt các filter từ phải sang trái, từ trên xuống dưới, mỗi lần một pixel. Với mỗi pixel tương ứng trong cửa sổ trượt, ta sẽ nhân giá trị của nó với trọng số trong filter rồi cộng lại với nhau.\n",
        "\n",
        "        ![](https://drive.google.com/uc?export=view&id=1riGOZlVlZdE-iAId6b23kaMLz7NncRT-)\n",
        "\n",
        "        ![](https://drive.google.com/uc?export=view&id=1M7zZWBg4Hr_aJ7OJZ1t_Y4s48DuYUSkq)\n",
        "\n",
        "    *   ***Tầng max-pooling:***\n",
        "\n",
        "        Với pool có kích thước là $p$x$p$, ta cũng lần lượt trượt các filter từ phải sang trái, từ trên xuống dưới, nhưng mỗi lần là $p$ pixel. Ta sẽ chọn ra giá trị lớn nhất trong cửa sổ trượt đó.\n",
        "\n",
        "        ![](https://drive.google.com/uc?export=view&id=1soCPEqlOsBjZNTap4opnfFF5rehv0anc)\n",
        "\n",
        "    *   ***Tầng fully connected:***\n",
        "\n",
        "        Ta sẽ có $k$ node tương đương với $k$ lớp cần phân, vì đây là tầng fully connected nên tất cả các node của tầng trước sẽ được nối với tất cả các node trong tầng này. Tức là giá trị đầu ra của mỗi node sẽ được tính bằng công thức sau: $t = w * x + b$ với $t$ là giá trị đầu ra của mỗi node, $w$ là vector chứa trọng số của node đó, $x$ là vector các giá trị đầu ra của tất cả các node ở tầng trước đó và $b$ là bias của node đó. Với $k$ node ta sẽ thu được một vector $k$ chiều và ta sẽ tính softmax của vector này, mỗi giá trị sẽ tương ứng với xác suất của mỗi lớp và ta sẽ chọn lớp nào có xác suất cao nhất.\n",
        "\n",
        "        Ta sẽ dùng độ đo cross-entropy để tính độ lỗi: $L=-\\text{ln}(p_c)$ với $p_c$ là xác suất của lớp đúng $c$.\n",
        "\n",
        "*   **Lan truyền ngược:**\n",
        "\n",
        "    Mục tiêu của việc học chỉ đơn giản là tối thiểu hoá độ lỗi. Để làm được điều đó, ta sẽ sử dụng kĩ thuật là Gradient Descent (GD), tức là ta phải tính gradient của hàm lỗi. Ở đây ta sẽ sử dụng một biến thể của GD là Stochastic Gradient Descent (SGD).\n",
        "    SGD cũng giống như GD nhưng thay vì cập nhật các trọng số và bias sau khi duyệt hết tập train, ta sẽ cập nhật với mỗi một batch được duyệt.\n",
        "\n",
        "    Trong quá trình này ta sẽ lần lượt tính các gradient của từng tầng bằng quy tắt mắc xích để cập nhật các trọng số và bias trong các tầng đó.\n",
        "\n",
        "    *   ***Tầng fully connected:***\n",
        "\n",
        "        Ta có thể dùng quy tắc mắc xích để tính các gradient sau của mỗi bức ảnh:\n",
        "        \\begin{equation}\n",
        "          \\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial {\\text{output}_\\text{FCL}}} * \\frac{\\partial {\\text{output}_\\text{FCL}}}{\\partial t} * \\frac{\\partial t}{\\partial w}\n",
        "        \\end{equation}\n",
        "        \\begin{equation}\n",
        "          \\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial {\\text{output}_\\text{FCL}}} * \\frac{\\partial {\\text{output}_\\text{FCL}}}{\\partial t} * \\frac{\\partial t}{\\partial b}\n",
        "        \\end{equation}\n",
        "        \\begin{equation}\n",
        "          \\frac{\\partial L}{\\partial {\\text{output}_\\text{MPL}}} = \\frac{\\partial L}{\\partial {\\text{output}_\\text{FCL}}} * \\frac{\\partial {\\text{output}_\\text{FCL}}}{\\partial t} * \\frac{\\partial t}{\\partial {\\text{output}_\\text{MPL}}}\n",
        "        \\end{equation}\n",
        "\n",
        "        Để tính gradient cho toàn bộ 1 batch, ta tính trung bình cộng các gradient của tất cả các ảnh có trong batch đó.\n",
        "\n",
        "        Sau đó, ta sẽ cập nhật các trọng số sau mỗi một batch được duyệt: $w_i = w_i - \\alpha * \\frac{\\partial L}{\\partial w}$ với $w_i$ là trọng số thứ $i$ và $\\alpha$ là hệ số học.\n",
        "\n",
        "        Tương tự, ta cũng cập nhật các bias: $b_i = b_i - \\alpha * \\frac{\\partial L}{\\partial b}$ với $b_i$ là bias thứ $i$ và $\\alpha$ là hệ số học.\n",
        "\n",
        "        Cuối cùng ta truyền $\\frac{\\partial L}{\\partial {\\text{output}_\\text{MPL}}}$ về cho tầng max-pooling.\n",
        "\n",
        "        Chi tiết các công thức có trong tài liệu tham khảo [2].\n",
        "\n",
        "    *   ***Tầng max-pooling:***\n",
        "\n",
        "        Vì tầng này không có trọng số nên ta không cần cập nhật gì cả. Ta chỉ cần khôi phục lại kích thước ban đầu của mảng trước khi đi qua tầng max-pooling, rồi gán $\\frac{\\partial L}{\\partial {\\text{output}_\\text{MPL}}}$ vào vị trí có giá trị lớn nhất trong cửa sổ trượt $p$x$p$ ban đầu, những vị trí còn lại sẽ được gán bằng 0. Đây chính là $\\frac{\\partial L}{\\partial {\\text{output}_\\text{CL}}}$.\n",
        "\n",
        "        ![](https://victorzhou.com/media/cnn-post/maxpool-backprop.svg)\n",
        "\n",
        "        <center><small>Nguồn: https://victorzhou.com/blog/intro-to-cnns-part-2/</small></center>\n",
        "\n",
        "        Ta sẽ truyền $\\frac{\\partial L}{\\partial {\\text{output}_\\text{CL}}}$ về cho tầng convolution.\n",
        "\n",
        "        Việc này được thực hiện độc lập nhau với tất cả các ảnh có trong 1 batch.\n",
        "\n",
        "    *   ***Tầng convolutional:***\n",
        "\n",
        "        Ta cũng dùng quy tắc mắc xích để tính gradient sau:\n",
        "        \\begin{equation}\n",
        "          \\frac{\\partial L}{\\partial \\text{filter}(x,y)} = \\sum\\limits_{i}\\sum\\limits_{j}\\frac{\\partial L}{\\partial {\\text{output}_\\text{CL}(i,j)}} * \\frac{\\partial {\\text{output}_\\text{CL}(i,j)}}{\\partial \\text{filter}(x,y)}\n",
        "        \\end{equation}\n",
        "\n",
        "        Tương tự, để tính gradient cho toàn bộ 1 batch, ta tính trung bình cộng các gradient của tất cả các ảnh có trong batch đó.\n",
        "\n",
        "        Ta cập nhật các trọng số của filter: $\\text{filter}(x,y) = \\text{filter}(x,y) - \\alpha * \\frac{\\partial L}{\\partial \\text{filter}(x,y)}$ với $\\text{filter}(x,y)$ là trọng số của filter ở dòng $x$ cột $y$ và $\\alpha$ là hệ số học.\n",
        "\n",
        "        Chi tiết các công thức có trong tài liệu tham khảo [2].\n",
        "\n",
        "*   Lặp lại cho tất cả các ảnh còn lại.\n",
        "    \n",
        "*   Nếu đã duyệt hết ảnh, ta sẽ thực hiện lại từ đầu, 1 vòng như vậy được gọi là 1 epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8pcWtQEQDIA"
      },
      "source": [
        "## **Đánh giá**\n",
        "\n",
        "*   Thử nghiệm trên tập dữ liệu chữ số viết tay MNIST. Tập dữ liệu này chứa các ảnh chữ số viết tay từ 0 đến 9, nó bao gồm 60000 ảnh trong tập train và 10000 ảnh trong tập test, mỗi ảnh có kích thước là 28x28 và là ảnh grayscale.\n",
        "\n",
        "*   Cấu hình của CNN như sau:\n",
        "\n",
        "  *   Convolutional tầng sẽ có 32 filter, mỗi filter sẽ có kích thước là 5x5.\n",
        "\n",
        "  *   Max pool tầng có kích thước của pool là 2x2.\n",
        "\n",
        "  *   Fully connected tầng sẽ có 10 node tương ứng với 10 chữ số từ 0 đến 9.\n",
        "\n",
        "  *   $\\alpha = 0.005$\n",
        "\n",
        "  *   epoch = 20\n",
        "\n",
        "  *   batch size = 100\n",
        "\n",
        "*   Kết quả: \n",
        "\n",
        "  *   Thời gian huấn luyện khá lâu khoảng 42 phút 54 giây cho 20 epoch với mỗi epoch khoảng 130 giây. Tỷ lệ chính xác khi train đạt khoảng 91% và tỷ lệ chính xác khi test đạt khoảng 92%.\n",
        "\n",
        "  *   Thời gian huấn luyện của keras nhanh hơn, chỉ 6 phút 16 giây cho 20 epoch với mỗi epoch khoảng 20 giây. Tỷ lệ chính xác khi train đạt khoảng 94% và tỷ lệ chính xác khi test cũng đạt khoảng 94%.\n",
        "\n",
        "  *   Nhóm vẫn chưa biết tại sao lại có sự khác biệt này."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ucstLHdJNRj",
        "outputId": "bb5c712c-e822-4588-a816-811719925f03"
      },
      "source": [
        "!python source.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Normalizing...\n",
            "Initiating parameters...\n",
            "\n",
            "--------------Our model--------------\n",
            "\n",
            "Epoch 1/20\n",
            "\t136s - loss: 0.9842 - accuracy: 0.7588 - val_loss: 0.4630 - val_accuracy: 0.8725\n",
            "Epoch 2/20\n",
            "\t129s - loss: 0.4273 - accuracy: 0.8790 - val_loss: 0.3716 - val_accuracy: 0.8917\n",
            "Epoch 3/20\n",
            "\t126s - loss: 0.3751 - accuracy: 0.8907 - val_loss: 0.3446 - val_accuracy: 0.9015\n",
            "Epoch 4/20\n",
            "\t130s - loss: 0.3538 - accuracy: 0.8971 - val_loss: 0.3261 - val_accuracy: 0.9063\n",
            "Epoch 5/20\n",
            "\t126s - loss: 0.3419 - accuracy: 0.8998 - val_loss: 0.3187 - val_accuracy: 0.9096\n",
            "Epoch 6/20\n",
            "\t130s - loss: 0.3336 - accuracy: 0.9021 - val_loss: 0.3149 - val_accuracy: 0.9088\n",
            "Epoch 7/20\n",
            "\t126s - loss: 0.3272 - accuracy: 0.9042 - val_loss: 0.3080 - val_accuracy: 0.9112\n",
            "Epoch 8/20\n",
            "\t129s - loss: 0.3223 - accuracy: 0.9054 - val_loss: 0.3025 - val_accuracy: 0.9126\n",
            "Epoch 9/20\n",
            "\t126s - loss: 0.3176 - accuracy: 0.9071 - val_loss: 0.2998 - val_accuracy: 0.9127\n",
            "Epoch 10/20\n",
            "\t130s - loss: 0.3137 - accuracy: 0.9080 - val_loss: 0.2964 - val_accuracy: 0.9150\n",
            "Epoch 11/20\n",
            "\t126s - loss: 0.3105 - accuracy: 0.9099 - val_loss: 0.2915 - val_accuracy: 0.9153\n",
            "Epoch 12/20\n",
            "\t130s - loss: 0.3071 - accuracy: 0.9109 - val_loss: 0.2894 - val_accuracy: 0.9158\n",
            "Epoch 13/20\n",
            "\t127s - loss: 0.3040 - accuracy: 0.9120 - val_loss: 0.2889 - val_accuracy: 0.9161\n",
            "Epoch 14/20\n",
            "\t129s - loss: 0.3013 - accuracy: 0.9121 - val_loss: 0.2819 - val_accuracy: 0.9194\n",
            "Epoch 15/20\n",
            "\t126s - loss: 0.2981 - accuracy: 0.9126 - val_loss: 0.2832 - val_accuracy: 0.9178\n",
            "Epoch 16/20\n",
            "\t129s - loss: 0.2949 - accuracy: 0.9146 - val_loss: 0.2770 - val_accuracy: 0.9206\n",
            "Epoch 17/20\n",
            "\t126s - loss: 0.2918 - accuracy: 0.9157 - val_loss: 0.2797 - val_accuracy: 0.9199\n",
            "Epoch 18/20\n",
            "\t129s - loss: 0.2896 - accuracy: 0.9161 - val_loss: 0.2769 - val_accuracy: 0.9212\n",
            "Epoch 19/20\n",
            "\t125s - loss: 0.2868 - accuracy: 0.9163 - val_loss: 0.2710 - val_accuracy: 0.9234\n",
            "Epoch 20/20\n",
            "\t129s - loss: 0.2835 - accuracy: 0.9175 - val_loss: 0.2698 - val_accuracy: 0.9237\n",
            "Total runtime: 00:42:54\n",
            "\n",
            "--------------Keras model--------------\n",
            "\n",
            "2021-06-09 11:20:21.017360: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Epoch 1/20\n",
            "600/600 - 20s - loss: 1.1418 - accuracy: 0.7349 - val_loss: 0.4868 - val_accuracy: 0.8745\n",
            "Epoch 2/20\n",
            "600/600 - 19s - loss: 0.4302 - accuracy: 0.8809 - val_loss: 0.3620 - val_accuracy: 0.8990\n",
            "Epoch 3/20\n",
            "600/600 - 19s - loss: 0.3619 - accuracy: 0.8960 - val_loss: 0.3229 - val_accuracy: 0.9086\n",
            "Epoch 4/20\n",
            "600/600 - 19s - loss: 0.3331 - accuracy: 0.9032 - val_loss: 0.3044 - val_accuracy: 0.9134\n",
            "Epoch 5/20\n",
            "600/600 - 19s - loss: 0.3151 - accuracy: 0.9080 - val_loss: 0.2885 - val_accuracy: 0.9167\n",
            "Epoch 6/20\n",
            "600/600 - 19s - loss: 0.3017 - accuracy: 0.9127 - val_loss: 0.2795 - val_accuracy: 0.9205\n",
            "Epoch 7/20\n",
            "600/600 - 19s - loss: 0.2904 - accuracy: 0.9159 - val_loss: 0.2706 - val_accuracy: 0.9213\n",
            "Epoch 8/20\n",
            "600/600 - 19s - loss: 0.2806 - accuracy: 0.9184 - val_loss: 0.2651 - val_accuracy: 0.9242\n",
            "Epoch 9/20\n",
            "600/600 - 19s - loss: 0.2711 - accuracy: 0.9217 - val_loss: 0.2537 - val_accuracy: 0.9272\n",
            "Epoch 10/20\n",
            "600/600 - 19s - loss: 0.2627 - accuracy: 0.9240 - val_loss: 0.2459 - val_accuracy: 0.9305\n",
            "Epoch 11/20\n",
            "600/600 - 19s - loss: 0.2546 - accuracy: 0.9268 - val_loss: 0.2385 - val_accuracy: 0.9317\n",
            "Epoch 12/20\n",
            "600/600 - 19s - loss: 0.2465 - accuracy: 0.9297 - val_loss: 0.2325 - val_accuracy: 0.9341\n",
            "Epoch 13/20\n",
            "600/600 - 19s - loss: 0.2386 - accuracy: 0.9316 - val_loss: 0.2243 - val_accuracy: 0.9363\n",
            "Epoch 14/20\n",
            "600/600 - 19s - loss: 0.2311 - accuracy: 0.9338 - val_loss: 0.2197 - val_accuracy: 0.9375\n",
            "Epoch 15/20\n",
            "600/600 - 19s - loss: 0.2240 - accuracy: 0.9366 - val_loss: 0.2132 - val_accuracy: 0.9398\n",
            "Epoch 16/20\n",
            "600/600 - 19s - loss: 0.2168 - accuracy: 0.9381 - val_loss: 0.2037 - val_accuracy: 0.9430\n",
            "Epoch 17/20\n",
            "600/600 - 19s - loss: 0.2101 - accuracy: 0.9408 - val_loss: 0.1981 - val_accuracy: 0.9436\n",
            "Epoch 18/20\n",
            "600/600 - 19s - loss: 0.2032 - accuracy: 0.9425 - val_loss: 0.1910 - val_accuracy: 0.9457\n",
            "Epoch 19/20\n",
            "600/600 - 19s - loss: 0.1970 - accuracy: 0.9448 - val_loss: 0.1853 - val_accuracy: 0.9481\n",
            "Epoch 20/20\n",
            "600/600 - 19s - loss: 0.1907 - accuracy: 0.9469 - val_loss: 0.1797 - val_accuracy: 0.9493\n",
            "Total runtime: 00:06:16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTnEOJceMiNC"
      },
      "source": [
        "# **3. Cài đặt song song (trên GPU)**\n",
        "\n",
        "*   **Phân tích:**\n",
        "*   **Thiết kế:**\n",
        "*   **Đánh giá:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY6xiR6NMkOC"
      },
      "source": [
        "# **4. Cài đặt song song (trên GPU) + tối ưu hóa**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt9Vym-5Mnpi"
      },
      "source": [
        "# **5. Nhìn lại quá trình làm đồ án**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-zg6xzbLTeU"
      },
      "source": [
        "# **6. Tài liệu tham khảo**\n",
        "\n",
        "[1] https://victorzhou.com/blog/intro-to-cnns-part-1/\n",
        "\n",
        "[2] https://victorzhou.com/blog/intro-to-cnns-part-2/\n",
        "\n",
        "[3] https://www.kaggle.com/moltean/fruits"
      ]
    }
  ]
}